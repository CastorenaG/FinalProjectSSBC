# -*- coding: utf-8 -*-
"""Proyecto Final Perceptrón Múltiple Employee.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1N9j2aOLqQS6qDm_bW9ZTp33-fEtjSc1B
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

df = pd.read_csv("/content/drive/MyDrive/ProyectoFinalSemBasCon/Employee.csv")

# Codificar las variables categóricas
df['Education'] = df['Education'].map({'Bachelors': 0, 'Masters': 1, 'PHD': 2})
df['City'] = df['City'].map({'Pune': 0, 'New Delhi': 1, 'Bangalore': 2})
df['Gender'] = df['Gender'].map({'Female': 0, 'Male': 1})
df['EverBenched'] = df['EverBenched'].map({'No': 0, 'Yes': 1})

# Agregar una columna de unos para el sesgo (bias)
df["bias"] = 1

# Separar los datos en características (X) y etiquetas (y)
X = df.drop("LeaveOrNot", axis=1).to_numpy()
y = df["LeaveOrNot"].to_numpy()

# Inicializar los pesos y sesgos de manera aleatoria
np.random.seed(0)
input_size = X.shape[1]
hidden_size = 4  # Número de neuronas en la capa oculta
output_size = 1  # Número de neuronas en la capa de salida
learning_rate = 0.01
num_epochs = 1000

weights_input_hidden = np.random.rand(input_size, hidden_size)
weights_hidden_output = np.random.rand(hidden_size, output_size)

bias_hidden = np.zeros((1, hidden_size))
bias_output = np.zeros((1, output_size))

# Definir la función de activación (sigmoide)
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

# Definir la derivada de la función de activación (para la retropropagación)
def sigmoid_derivative(x):
    return x * (1 - x)

# Entrenamiento del modelo
for epoch in range(num_epochs):
    # Capa de entrada a capa oculta
    hidden_input = np.dot(X, weights_input_hidden) + bias_hidden
    hidden_output = sigmoid(hidden_input)

    # Capa oculta a capa de salida
    output_input = np.dot(hidden_output, weights_hidden_output) + bias_output
    predicted_output = sigmoid(output_input)

    # Calcular el error
    error = y.reshape(-1, 1) - predicted_output

    # Calcular el error cuadrático medio (MSE)
    mse = np.mean(error**2)

    # Retropropagación
    output_delta = error * sigmoid_derivative(predicted_output)
    hidden_error = output_delta.dot(weights_hidden_output.T)
    hidden_delta = hidden_error * sigmoid_derivative(hidden_output)

    # Actualizar pesos y sesgos
    weights_hidden_output += learning_rate * hidden_output.T.dot(output_delta)
    weights_input_hidden += learning_rate * X.T.dot(hidden_delta)
    bias_output += learning_rate * np.sum(output_delta, axis=0, keepdims=True)
    bias_hidden += learning_rate * np.sum(hidden_delta, axis=0, keepdims=True)

# Realizar predicciones
hidden_input = np.dot(X, weights_input_hidden) + bias_hidden
hidden_output = sigmoid(hidden_input)
output_input = np.dot(hidden_output, weights_hidden_output) + bias_output
predictions = sigmoid(output_input)

# Convertir las predicciones a etiquetas binarias (0 o 1)
predictions_binary = (predictions >= 0.5).astype(int)

# Evaluación del modelo
accuracy = np.mean(predictions_binary.flatten() == y)
print("Precisión del modelo:", accuracy)